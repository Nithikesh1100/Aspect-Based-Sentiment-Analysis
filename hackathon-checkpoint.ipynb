{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85142e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"100s\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Test Spark Session\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48286ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- address: string (nullable = true)\n",
      " |-- attributes: struct (nullable = true)\n",
      " |    |-- AcceptsInsurance: string (nullable = true)\n",
      " |    |-- AgesAllowed: string (nullable = true)\n",
      " |    |-- Alcohol: string (nullable = true)\n",
      " |    |-- Ambience: string (nullable = true)\n",
      " |    |-- BYOB: string (nullable = true)\n",
      " |    |-- BYOBCorkage: string (nullable = true)\n",
      " |    |-- BestNights: string (nullable = true)\n",
      " |    |-- BikeParking: string (nullable = true)\n",
      " |    |-- BusinessAcceptsBitcoin: string (nullable = true)\n",
      " |    |-- BusinessAcceptsCreditCards: string (nullable = true)\n",
      " |    |-- BusinessParking: string (nullable = true)\n",
      " |    |-- ByAppointmentOnly: string (nullable = true)\n",
      " |    |-- Caters: string (nullable = true)\n",
      " |    |-- CoatCheck: string (nullable = true)\n",
      " |    |-- Corkage: string (nullable = true)\n",
      " |    |-- DietaryRestrictions: string (nullable = true)\n",
      " |    |-- DogsAllowed: string (nullable = true)\n",
      " |    |-- DriveThru: string (nullable = true)\n",
      " |    |-- GoodForDancing: string (nullable = true)\n",
      " |    |-- GoodForKids: string (nullable = true)\n",
      " |    |-- GoodForMeal: string (nullable = true)\n",
      " |    |-- HairSpecializesIn: string (nullable = true)\n",
      " |    |-- HappyHour: string (nullable = true)\n",
      " |    |-- HasTV: string (nullable = true)\n",
      " |    |-- Music: string (nullable = true)\n",
      " |    |-- NoiseLevel: string (nullable = true)\n",
      " |    |-- Open24Hours: string (nullable = true)\n",
      " |    |-- OutdoorSeating: string (nullable = true)\n",
      " |    |-- RestaurantsAttire: string (nullable = true)\n",
      " |    |-- RestaurantsCounterService: string (nullable = true)\n",
      " |    |-- RestaurantsDelivery: string (nullable = true)\n",
      " |    |-- RestaurantsGoodForGroups: string (nullable = true)\n",
      " |    |-- RestaurantsPriceRange2: string (nullable = true)\n",
      " |    |-- RestaurantsReservations: string (nullable = true)\n",
      " |    |-- RestaurantsTableService: string (nullable = true)\n",
      " |    |-- RestaurantsTakeOut: string (nullable = true)\n",
      " |    |-- Smoking: string (nullable = true)\n",
      " |    |-- WheelchairAccessible: string (nullable = true)\n",
      " |    |-- WiFi: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- hours: struct (nullable = true)\n",
      " |    |-- Friday: string (nullable = true)\n",
      " |    |-- Monday: string (nullable = true)\n",
      " |    |-- Saturday: string (nullable = true)\n",
      " |    |-- Sunday: string (nullable = true)\n",
      " |    |-- Thursday: string (nullable = true)\n",
      " |    |-- Tuesday: string (nullable = true)\n",
      " |    |-- Wednesday: string (nullable = true)\n",
      " |-- is_open: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150346"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business = spark.read.json(r\"C:\\Users\\NITHIKESH\\Downloads\\extracted\\dataset\\yelp_academic_dataset_business.json\")\n",
    "business.printSchema()\n",
    "business.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13b5f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6990280"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = spark.read.json(r\"C:\\Users\\NITHIKESH\\Downloads\\extracted\\dataset\\yelp_academic_dataset_review.json\")\n",
    "review.printSchema()\n",
    "review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcea9b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- compliment_count: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "908915"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip = spark.read.json(r\"C:\\Users\\NITHIKESH\\Downloads\\extracted\\dataset\\yelp_academic_dataset_tip.json\")\n",
    "tip.printSchema()\n",
    "tip.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7dc7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119698"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business=business.select(\"business_id\",\"name\",\"review_count\",\"is_open\")\n",
    "business = business.filter(business.is_open == 1)\n",
    "business.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ebecd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6990280"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=review.select('user_id' ,'business_id', 'stars','text')\n",
    "review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d956a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "tip=tip.select('user_id' ,'business_id', 'text')\n",
    "tip = tip.withColumnRenamed(\"text\", \"tip_text\")\n",
    "# tip.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c32cd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+------------+-------+\n",
      "|         business_id|             user_id|stars|                text|                name|review_count|is_open|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+------------+-------+\n",
      "|XQfwVwDr-v0ZS3_Cb...|mh_-eMZ6K5RLWhZyI...|  3.0|If you decide to ...|Turning Point of ...|         169|      1|\n",
      "|YjUWPpI6HXG530lwP...|8g_iMtfSiwikVnbP2...|  3.0|Family diner. Had...|   Kettle Restaurant|          47|      1|\n",
      "|kxX2SOes4o-D3ZQBk...|_7bHUi9Uuf5__HHc_...|  5.0|Wow!  Yummy, diff...|               Zaika|         181|      1|\n",
      "|gmjsEdUsKpj9Xxu6p...|r3zeYsv1XFBRA4dJp...|  5.0|Loved this tour! ...|The Voodoo Bone L...|         359|      1|\n",
      "|B5XSoSG3SfvQGtKEG...|wSTuiTk-sKNdcFypr...|  3.0|This easter inste...|Los Padres Nation...|          13|      1|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = review.join(business, on=\"business_id\", how=\"inner\")\n",
    "\n",
    "# Show the result\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f5c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- tip_text: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- is_open: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+-----+--------------------+--------------------+------------+-------+\n",
      "|         business_id|             user_id|            tip_text|stars|                text|                name|review_count|is_open|\n",
      "+--------------------+--------------------+--------------------+-----+--------------------+--------------------+------------+-------+\n",
      "|-0TffRSXXIlBYVbb5...|8e2bnPezIoW8ySZ0A...|Great food and Li...|  5.0|Great food and Li...|IndeBlue Modern I...|        1097|      1|\n",
      "|-0YvX6VK5S0u_hbQF...|T9tYtHUKNmJE1N6Ar...|Don't believe tho...|  1.0|Don't believe tho...| European Motorworks|           9|      1|\n",
      "|-0iIxySkp97WNlwK6...|cRANsQ5E_sxeQ0Aoo...|Get the hummus, i...|  4.0|I met a friend he...|Truckee Bagel Com...|         219|      1|\n",
      "|-0iIxySkp97WNlwK6...|lRRVRehFcudfbjY6y...|JalapeÃ±o bagel is...|  5.0|I definitely had ...|Truckee Bagel Com...|         219|      1|\n",
      "|-0iIxySkp97WNlwK6...|lRRVRehFcudfbjY6y...|Cranberry is a li...|  5.0|I definitely had ...|Truckee Bagel Com...|         219|      1|\n",
      "+--------------------+--------------------+--------------------+-----+--------------------+--------------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform an inner join on 'business_id' and 'user_id'\n",
    "df_merged = tip.join(df, on=[\"business_id\", \"user_id\"], how=\"inner\")\n",
    "\n",
    "# Show the schema and result of the merged DataFrame\n",
    "df_merged.printSchema()\n",
    "df_merged.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8966c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- tip_text: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- is_open: long (nullable = true)\n",
      " |-- full_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, col, lit\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df = df_merged.withColumn(\"full_text\", concat(col(\"text\"), lit(\" \"), col(\"tip_text\")))\n",
    "\n",
    "# Show the DataFrame to verify the concatenation\n",
    "# df.show(truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a828ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+-----------------+--------------------+\n",
      "|         business_id|             user_id|stars|             name|           full_text|\n",
      "+--------------------+--------------------+-----+-----------------+--------------------+\n",
      "|---kPU91CF4Lq2-Wl...|zmgsdGzOp08BWJZ2y...|  5.0|Frankie's Raw Bar|Awesome raw bar /...|\n",
      "|--LC8cIrALInl2vyo...|lVW0BD_ZkWVGDVwBu...|  4.0|   Studio G Salon|Kathy at Studio G...|\n",
      "+--------------------+--------------------+-----+-----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- full_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first, col\n",
    "\n",
    "# Drop the specified columns\n",
    "df_dropped = df.drop(\"text\", \"tip_text\", \"is_open\", \"review_count\")\n",
    "\n",
    "# Group by 'business_id' and aggregate the remaining columns\n",
    "# Here we use 'first' to keep the first value in each group; adjust as needed\n",
    "df_grouped = df_dropped.groupBy(\"business_id\").agg(\n",
    "    first(\"user_id\").alias(\"user_id\"),\n",
    "    first(\"stars\").alias(\"stars\"),\n",
    "    first(\"name\").alias(\"name\"),\n",
    "    first(\"full_text\").alias(\"full_text\")\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_grouped.show(2)\n",
    "df_grouped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cfc872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NITHIKESH\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+-----------------+--------------------+\n",
      "|         business_id|             user_id|stars|             name|             aspects|\n",
      "+--------------------+--------------------+-----+-----------------+--------------------+\n",
      "|---kPU91CF4Lq2-Wl...|zmgsdGzOp08BWJZ2y...|  5.0|Frankie's Raw Bar|{Ambiance -> [Awe...|\n",
      "|--LC8cIrALInl2vyo...|lVW0BD_ZkWVGDVwBu...|  4.0|   Studio G Salon|{Cleanliness -> [...|\n",
      "+--------------------+--------------------+-----+-----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import MapType, StringType, ArrayType\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "# Load the aspect-based sentiment analysis pipeline using a fine-tuned model\n",
    "absa_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define the aspects you want to extract\n",
    "aspects = ['Food Quality', 'Service', 'Ambiance', 'Pricing', 'Cleanliness']\n",
    "\n",
    "# Sample function to split text into sentences\n",
    "def simple_sentence_tokenizer(text):\n",
    "    sentences = text.replace('\\n', ' ').split('.')\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "# Function to extract aspects using zero-shot classification\n",
    "def extract_aspects_absa(text, aspects):\n",
    "    # Tokenize text into individual sentences\n",
    "    sentences = simple_sentence_tokenizer(text)\n",
    "    \n",
    "    aspect_results = {aspect: [] for aspect in aspects}  # To store relevant sentences for each aspect\n",
    "    \n",
    "    # For each sentence, perform zero-shot classification for each aspect\n",
    "    for sentence in sentences:\n",
    "        for aspect in aspects:\n",
    "            # Run zero-shot classification for the current aspect\n",
    "            result = absa_model(sentence, candidate_labels=[aspect])\n",
    "            \n",
    "            # Check if the aspect score is higher than 0.5\n",
    "            if result['scores'][0] > 0.5:\n",
    "                aspect_results[aspect].append(sentence)\n",
    "    \n",
    "    return {aspect: sentences for aspect, sentences in aspect_results.items() if sentences}\n",
    "\n",
    "# Register a PySpark UDF to perform aspect extraction\n",
    "extract_aspects_udf = udf(lambda full_text: extract_aspects_absa(full_text, aspects), MapType(StringType(), ArrayType(StringType())))\n",
    "\n",
    "df_with_aspects = df_grouped.withColumn(\"aspects\", extract_aspects_udf(df_grouped[\"full_text\"]))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_with_aspects.select(\"business_id\", \"user_id\", \"stars\", \"name\", \"aspects\").show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0e4c99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+-----------------+--------------------+--------------------+\n",
      "|         business_id|             user_id|stars|             name|             aspects|   sentiment_summary|\n",
      "+--------------------+--------------------+-----+-----------------+--------------------+--------------------+\n",
      "|---kPU91CF4Lq2-Wl...|zmgsdGzOp08BWJZ2y...|  5.0|Frankie's Raw Bar|{Ambiance -> [Awe...|{Ambiance -> {neu...|\n",
      "|--LC8cIrALInl2vyo...|lVW0BD_ZkWVGDVwBu...|  4.0|   Studio G Salon|{Cleanliness -> [...|{Cleanliness -> {...|\n",
      "+--------------------+--------------------+-----+-----------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import MapType, StringType, ArrayType\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline using a model\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Define the function to analyze sentiment for a list of sentences\n",
    "def analyze_sentiments(sentences):\n",
    "    sentiment_results = {\"positive\": [], \"neutral\": [], \"negative\": []}\n",
    "    \n",
    "    if not sentences:\n",
    "        return sentiment_results\n",
    "\n",
    "    for sentence in sentences:\n",
    "        result = sentiment_model(sentence)\n",
    "        sentiment_label = result[0]['label']\n",
    "        \n",
    "        # Adjust these mappings based on the actual labels used by the model\n",
    "        if sentiment_label == 'POSITIVE':  # Example for positive sentiment\n",
    "            sentiment_results[\"positive\"].append(sentence)\n",
    "        elif sentiment_label == 'NEGATIVE':  # Example for negative sentiment\n",
    "            sentiment_results[\"negative\"].append(sentence)\n",
    "        else:  # Neutral sentiment (if supported or needed)\n",
    "            sentiment_results[\"neutral\"].append(sentence)\n",
    "    \n",
    "    return sentiment_results\n",
    "\n",
    "# Register a PySpark UDF to perform sentiment analysis on the aspects\n",
    "def analyze_sentiments_udf(aspects):\n",
    "    sentiment_summary = {}\n",
    "    if aspects:\n",
    "        for aspect, sentences in aspects.items():\n",
    "            sentiment_summary[aspect] = analyze_sentiments(sentences)\n",
    "    return sentiment_summary\n",
    "\n",
    "# Register the UDF with Spark\n",
    "analyze_sentiments_udf = udf(analyze_sentiments_udf, MapType(StringType(), MapType(StringType(), ArrayType(StringType()))))\n",
    "\n",
    "# Assuming df_with_aspects is your DataFrame with the 'aspects' column\n",
    "df_with_sentiments = df_with_aspects.withColumn(\"sentiment_summary\", analyze_sentiments_udf(df_with_aspects[\"aspects\"]))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_with_sentiments.select(\"business_id\", \"user_id\", \"stars\", \"name\", \"aspects\", \"sentiment_summary\").show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e4eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
